{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import  data_reader, data_loader\n",
    "from modules.sr import result_saver\n",
    "from modules.models import lag_llama\n",
    "from modules.experiment.tscv import get_tscv_results, get_summary, extract_metrics\n",
    "from modules.visualization import graphs\n",
    "from modules.fine_tuning import lag_llama_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nprint(os.getcwd())\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom datetime import datetime\\n\\n# Get the current date and time\\ncurrent_datetime = datetime.now()\\n\\n# Format the date and time as a string\\ndatetime_str = current_datetime.strftime(\"%Y-%d-%m %H:%M:%S\")\\n\\n# Return the date and time as a string\\nNOW = datetime_str\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "datetime_str = current_datetime.strftime(\"%Y-%d-%m %H:%M:%S\")\n",
    "\n",
    "# Return the date and time as a string\n",
    "NOW = datetime_str\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "#constraint: FOLDS x PREDICTION_LENGTH + TRAIN_SIZE !!must not!! be bigger than len(data)\n",
    "\n",
    "PREDICTION_LENGTH = 1 # currentlz only works for PREDICTION_LENGTH > 1\n",
    "TICKER = \"AAPL\"\n",
    "FREQUENCY = \"daily\" # currently we only have dailz frequency\n",
    "TYPE_OF_DATA = \"stock\" # currently we only have stock prices saved\n",
    "MODELS = [\"arima\", \"llama\", \"autoregressor\", \"fine-tuned Llama\"] # currentlz works onlz for these two\n",
    "#FOLDS = 10 # for TSCV # reduced to two for testing purposes\n",
    "CONTEXT_LENGTH = 245 # set to 245 for testing purposes\n",
    "METRICS = ['r2', 'mse', 'mae', 'rmse', 'mda', \"mape\"]\n",
    "\n",
    "# fine-tuning parameters\n",
    "BATCH_SIZE = 10\n",
    "MAX_EPOCHS = 5\n",
    "\n",
    "# data parameters\n",
    "FT_START_DATE = \"2022-07-07\"\n",
    "START_DATE = \"2023-07-07\"\n",
    "END_DATE = \"2024-07-07\"\n",
    "\n",
    "# want to add\n",
    "#TRAIN_PERIOD = # context lenghts. Should take a look into this\n",
    "TRAIN_SIZE = CONTEXT_LENGTH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY)\\n# this is just in case there are more CSVs of the same type and frequency, the data should be the first in the list\\n#if len(data) > 1:\\ndata = data[0]\\n\\nsimple_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"simple\"])\\n#if len(simple_data) > 1:\\nsimple_data = simple_data[0]\\n\\ntrain_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"train\"])\\ntrain_data = train_data[0]\\n\\ntest_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"test\"])\\ntest_data = test_data[0]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY)\n",
    "# this is just in case there are more CSVs of the same type and frequency, the data should be the first in the list\n",
    "#if len(data) > 1:\n",
    "data = data[0]\n",
    "\n",
    "simple_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"simple\"])\n",
    "#if len(simple_data) > 1:\n",
    "simple_data = simple_data[0]\n",
    "\n",
    "train_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"train\"])\n",
    "train_data = train_data[0]\n",
    "\n",
    "test_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"test\"])\n",
    "test_data = test_data[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CONFIG = {\"ticker\" : TICKER,\n",
    "               \"frequency\" : FREQUENCY,\n",
    "               \"start\" : START_DATE,\n",
    "               \"end\" : END_DATE}\n",
    "\n",
    "FT_DATA_CONFIG = {\"ticker\" : TICKER,\n",
    "                     \"frequency\" : FREQUENCY,\n",
    "                     \"start\" : FT_START_DATE,\n",
    "                     \"end\" : START_DATE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = data_loader.get_data(data_type=TYPE_OF_DATA, kwargs=DATA_CONFIG)\n",
    "ft_data = data_loader.get_data(data_type=TYPE_OF_DATA, kwargs=FT_DATA_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LENGTH = len(data)\n",
    "FT_LENGTH = len(ft_data)\n",
    "FOLDS = int((DATA_LENGTH - TRAIN_SIZE) / PREDICTION_LENGTH) # this calculates max ammount of folds we can have given a set TRAIN_SIZE and PREDICTION_LENGTH\n",
    "FOLDS = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | LagLlamaModel      | 2.4 M \n",
      "1 | augmentations | ApplyAugmentations | 0     \n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6050a876505446ff838ed8305ba6ffe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.03859 (best 4.03859), saving model to 'c:\\\\Users\\\\topco\\\\Dokumenti\\\\MSc Banking and Digital Finance UCL\\\\Modules\\\\Dissertation\\\\MSc_dissertation\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 3.19089 (best 3.19089), saving model to 'c:\\\\Users\\\\topco\\\\Dokumenti\\\\MSc Banking and Digital Finance UCL\\\\Modules\\\\Dissertation\\\\MSc_dissertation\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 3.05218 (best 3.05218), saving model to 'c:\\\\Users\\\\topco\\\\Dokumenti\\\\MSc Banking and Digital Finance UCL\\\\Modules\\\\Dissertation\\\\MSc_dissertation\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 2.65978 (best 2.65978), saving model to 'c:\\\\Users\\\\topco\\\\Dokumenti\\\\MSc Banking and Digital Finance UCL\\\\Modules\\\\Dissertation\\\\MSc_dissertation\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 2.46775 (best 2.46775), saving model to 'c:\\\\Users\\\\topco\\\\Dokumenti\\\\MSc Banking and Digital Finance UCL\\\\Modules\\\\Dissertation\\\\MSc_dissertation\\\\lightning_logs\\\\version_5\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d519d7652a4665a2a799f0ad280491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forecasting batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/6 finished in: 10.70 seconds\n",
      "Prediction from   2024-06-27 00:00:00   until   2024-06-27 00:00:00\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98c9f259fdc465e9cbd481f167a6f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forecasting batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/6 finished in: 11.22 seconds\n",
      "Prediction from   2024-06-28 00:00:00   until   2024-06-28 00:00:00\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60060ef5c51b4d199015ed0d49ddcd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forecasting batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/6 finished in: 10.51 seconds\n",
      "Prediction from   2024-07-01 00:00:00   until   2024-07-01 00:00:00\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98af3d298aa34f2d8031dbaf1c72bf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forecasting batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/6 finished in: 10.61 seconds\n",
      "Prediction from   2024-07-02 00:00:00   until   2024-07-02 00:00:00\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8f59db73df42d1bac9397ec278b2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forecasting batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/6 finished in: 10.01 seconds\n",
      "Prediction from   2024-07-03 00:00:00   until   2024-07-03 00:00:00\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\_auto_solvers.py:524: ModelFitWarning: Error fitting  ARIMA(5,0,0)(0,0,0)[0]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\_auto_solvers.py\", line 508, in _fit_candidate_model\n",
      "    fit.fit(y, X=X, **fit_params)\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\arima.py\", line 603, in fit\n",
      "    self._fit(y, X, **fit_args)\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\arima.py\", line 524, in _fit\n",
      "    fit, self.arima_res_ = _fit_wrapper()\n",
      "                           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\arima.py\", line 510, in _fit_wrapper\n",
      "    fitted = arima.fit(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\", line 704, in fit\n",
      "    mlefit = super(MLEModel, self).fit(start_params, method=method,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\model.py\", line 563, in fit\n",
      "    xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\optimizer.py\", line 241, in _fit\n",
      "    xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\optimizer.py\", line 651, in _fit_lbfgs\n",
      "    retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 237, in fmin_l_bfgs_b\n",
      "    res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 407, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 296, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 262, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 163, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 145, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\model.py\", line 531, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\", line 939, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py\", line 983, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py\", line 903, in _filter\n",
      "    self._initialize_state(prefix=prefix, complex_step=complex_step)\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\representation.py\", line 983, in _initialize_state\n",
      "    self._statespaces[prefix].initialize(self.initialization,\n",
      "  File \"statsmodels\\tsa\\statespace\\_representation.pyx\", line 1362, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels\\tsa\\statespace\\_initialization.pyx\", line 288, in statsmodels.tsa.statespace._initialization.dInitialization.initialize\n",
      "  File \"statsmodels\\tsa\\statespace\\_initialization.pyx\", line 406, in statsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\n",
      "  File \"statsmodels\\tsa\\statespace\\_tools.pyx\", line 1206, in statsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\n",
      "numpy.linalg.LinAlgError: LU decomposition error.\n",
      "\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3581e1e07b964e64b75fb2766faec8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forecasting batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6/6 finished in: 10.07 seconds\n",
      "Prediction from   2024-07-05 00:00:00   until   2024-07-05 00:00:00\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "r, p = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY,\n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mda</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arima</th>\n",
       "      <td>0.450407</td>\n",
       "      <td>14.482253</td>\n",
       "      <td>3.190176</td>\n",
       "      <td>3.805556</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.014594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_llama</th>\n",
       "      <td>-58.940031</td>\n",
       "      <td>1579.470616</td>\n",
       "      <td>38.714596</td>\n",
       "      <td>39.742554</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.176560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autoregressor</th>\n",
       "      <td>0.447312</td>\n",
       "      <td>14.563802</td>\n",
       "      <td>3.341670</td>\n",
       "      <td>3.816255</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.015282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft_lag_llama</th>\n",
       "      <td>-0.700098</td>\n",
       "      <td>44.799023</td>\n",
       "      <td>5.472705</td>\n",
       "      <td>6.693207</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.025150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      r2          mse        mae       rmse  mda      mape\n",
       "arima           0.450407    14.482253   3.190176   3.805556  0.6  0.014594\n",
       "lag_llama     -58.940031  1579.470616  38.714596  39.742554  0.2  0.176560\n",
       "autoregressor   0.447312    14.563802   3.341670   3.816255  0.6  0.015282\n",
       "ft_lag_llama   -0.700098    44.799023   5.472705   6.693207  0.6  0.025150"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arima</th>\n",
       "      <th>lag_llama</th>\n",
       "      <th>autoregressor</th>\n",
       "      <th>ft_lag_llama</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213.656341</td>\n",
       "      <td>178.009499</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>218.587265</td>\n",
       "      <td>214.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214.125477</td>\n",
       "      <td>188.782514</td>\n",
       "      <td>214.100006</td>\n",
       "      <td>215.746447</td>\n",
       "      <td>210.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210.232611</td>\n",
       "      <td>177.785137</td>\n",
       "      <td>210.619995</td>\n",
       "      <td>203.581973</td>\n",
       "      <td>216.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217.310340</td>\n",
       "      <td>176.589256</td>\n",
       "      <td>216.750000</td>\n",
       "      <td>217.426447</td>\n",
       "      <td>220.270004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.542241</td>\n",
       "      <td>181.412634</td>\n",
       "      <td>220.270004</td>\n",
       "      <td>220.673695</td>\n",
       "      <td>221.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>221.632904</td>\n",
       "      <td>174.763386</td>\n",
       "      <td>221.550003</td>\n",
       "      <td>220.005372</td>\n",
       "      <td>226.339996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        arima   lag_llama  autoregressor  ft_lag_llama      actual\n",
       "0  213.656341  178.009499     213.250000    218.587265  214.100006\n",
       "1  214.125477  188.782514     214.100006    215.746447  210.619995\n",
       "2  210.232611  177.785137     210.619995    203.581973  216.750000\n",
       "3  217.310340  176.589256     216.750000    217.426447  220.270004\n",
       "4  220.542241  181.412634     220.270004    220.673695  221.550003\n",
       "5  221.632904  174.763386     221.550003    220.005372  226.339996"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"PREDICTION_LENGTH={PREDICTION_LENGTH}__TICKER={TICKER}__FREQUENCY={FREQUENCY}__TYPE_OF_DATA={TYPE_OF_DATA}__FOLDS={FOLDS}__CONTEXT_LENGTH/TRAIN_SIZE={CONTEXT_LENGTH}__FT_START_DATE={FT_START_DATE}__START_DATE={START_DATE}__END_DATE={END_DATE}__FT_LENGTH={FT_LENGTH}__DATA_LENGTH={DATA_LENGTH}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"P_L={PREDICTION_LENGTH}__T={TICKER}__FR={FREQUENCY}__T_O_D={TYPE_OF_DATA}__FO={FOLDS}__C_L_T_S={CONTEXT_LENGTH}__FT_S_D={FT_START_DATE}__S_D={START_DATE}__E_D={END_DATE}__FT_L={FT_LENGTH}__D_L={DATA_LENGTH}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P_L=1__T=AAPL__FR=daily__T_O_D=stock__FO=6__C_L_T_S=245__FT_S_D=2022-07-07__S_D=2023-07-07__E_D=2024-07-07__FT_L=251__D_L=251.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to 'c:\\Users\\topco\\Dokumenti\\MSc Banking and Digital Finance UCL\\Modules\\Dissertation\\MSc_dissertation\\results\\evaluation\\P_L=1__T=AAPL__FR=daily__T_O_D=stock__FO=6__C_L_T_S=245__FT_S_D=2022-07-07__S_D=2023-07-07__E_D=2024-07-07__FT_L=251__D_L=251.csv'.\n",
      "Data has been written to 'c:\\Users\\topco\\Dokumenti\\MSc Banking and Digital Finance UCL\\Modules\\Dissertation\\MSc_dissertation\\results\\prediction\\P_L=1__T=AAPL__FR=daily__T_O_D=stock__FO=6__C_L_T_S=245__FT_S_D=2022-07-07__S_D=2023-07-07__E_D=2024-07-07__FT_L=251__D_L=251.csv'.\n"
     ]
    }
   ],
   "source": [
    "result_saver.save_results(r, experiment_name, type=\"evaluation\")\n",
    "result_saver.save_results(p, experiment_name, type=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p, a = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY, \n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the summary for each model\n",
    "s = [get_summary(r[i]) for i in range(len(r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df, medians_df, stds_df = extract_metrics(s, MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.standard_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.interactive_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.prediction_visualisation(MODELS, p, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEL the graph\n",
    "label the axes with timestamps\n",
    "show the history of the actual\n",
    "table of comparison, not just graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
