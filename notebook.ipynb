{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import  data_reader, data_loader\n",
    "from modules.sr import result_saver\n",
    "from modules.models import lag_llama\n",
    "from modules.experiment.tscv import get_tscv_results, get_summary, extract_metrics\n",
    "from modules.visualization import graphs\n",
    "from modules.fine_tuning import lag_llama_ft\n",
    "from modules.models import prpht\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earliest monthly data for S&P500 is 1985\n",
    "FTSE 100 also 1985\n",
    "NASDAQ also 1985\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from modules.data import data_loader\n",
    "\n",
    "a = data_loader.get_data(type = \"index\",ticker=\"S&P 500\", frequency = \"weekly\", start = \"2021-01-01\", end = \"2024-01-01\", rtrn = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3803.790039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>3795.540039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>3853.070068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>3787.379883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>3871.739990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>4585.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>4719.549805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>4746.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>4783.350098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>4769.830078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds            y\n",
       "0   2021-01-01  3803.790039\n",
       "1   2021-01-08  3795.540039\n",
       "2   2021-01-15  3853.070068\n",
       "3   2021-01-22  3787.379883\n",
       "4   2021-01-29  3871.739990\n",
       "..         ...          ...\n",
       "152 2023-12-01  4585.589844\n",
       "153 2023-12-08  4719.549805\n",
       "154 2023-12-15  4746.750000\n",
       "155 2023-12-22  4783.350098\n",
       "156 2023-12-29  4769.830078\n",
       "\n",
       "[157 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtlats\\__init__.py:5: FutureWarning: This package is deprecated, please install nixtla instead.\n",
      "  warnings.warn(\"This package is deprecated, please install nixtla instead.\", category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 1 calculated\n",
      "error 2 calculated\n",
      "error 3 calculated\n",
      "error 4 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: W-FRI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 5 calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Restricting input...\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: W-FRI\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Your time series data is too short Please be sure that your unique time series contain at least 64 observations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arima_hybrid\n\u001b[1;32m----> 3\u001b[0m pr \u001b[38;5;241m=\u001b[39m \u001b[43marima_hybrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_arima_timegpt_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweekly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_train_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\topco\\Dokumenti\\MSc Banking and Digital Finance UCL\\Modules\\Dissertation\\MSc_dissertation\\modules\\models\\arima_hybrid.py:49\u001b[0m, in \u001b[0;36mget_arima_timegpt_predictions\u001b[1;34m(data, prediction_horizon, frequency, error_train_size)\u001b[0m\n\u001b[0;32m     46\u001b[0m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#x[\"x2\"] = actual\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m error_forecast \u001b[38;5;241m=\u001b[39m \u001b[43mtimegpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_timegpt_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_horizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m arima\u001b[38;5;241m.\u001b[39mget_autoarima(data)\n\u001b[0;32m     52\u001b[0m forecast \u001b[38;5;241m=\u001b[39m arima\u001b[38;5;241m.\u001b[39mautoarima_predictions(model, prediction_horizon)\n",
      "File \u001b[1;32mc:\\Users\\topco\\Dokumenti\\MSc Banking and Digital Finance UCL\\Modules\\Dissertation\\MSc_dissertation\\modules\\models\\timegpt.py:45\u001b[0m, in \u001b[0;36mget_timegpt_forecast\u001b[1;34m(data, prediction_length, frequency, ft_steps, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(data, x, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ft_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m     forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mnixtla_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinetune_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mft_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_df_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     forecast_df \u001b[38;5;241m=\u001b[39m nixtla_client\u001b[38;5;241m.\u001b[39mforecast(df \u001b[38;5;241m=\u001b[39m data, X_df\u001b[38;5;241m=\u001b[39mx_df_future, h\u001b[38;5;241m=\u001b[39mprediction_length, time_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m\"\u001b[39m, target_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:60\u001b[0m, in \u001b[0;36mdeprecated_argument.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m argument duplicated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m     kwargs[new_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old_name)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:60\u001b[0m, in \u001b[0;36mdeprecated_argument.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m argument duplicated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m     kwargs[new_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old_name)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:1316\u001b[0m, in \u001b[0;36mNixtlaClient.forecast\u001b[1;34m(self, df, h, freq, id_col, time_col, target_col, X_df, level, quantiles, finetune_steps, finetune_loss, clean_ex_first, validate_api_key, add_history, date_features, date_features_to_one_hot, model, num_partitions)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forecast your time series using TimeGPT.\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \n\u001b[0;32m   1241\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    predictions (if level is not None).\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m-> 1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinetune_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetune_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinetune_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetune_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclean_ex_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_ex_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_features_to_one_hot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_features_to_one_hot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_partitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1337\u001b[0m     dist_nixtla_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instantiate_distributed_nixtla_client()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:742\u001b[0m, in \u001b[0;36mvalidate_model_parameter.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupported_models:\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    739\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    740\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupported_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    741\u001b[0m         )\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:760\u001b[0m, in \u001b[0;36mpartition_by_uid.<locals>.wrapper\u001b[1;34m(self, num_partitions, **kwargs)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_partitions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_partitions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_partitions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 760\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m     df \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    762\u001b[0m     X_df \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_df\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:988\u001b[0m, in \u001b[0;36m_NixtlaClient._forecast\u001b[1;34m(self, df, h, freq, id_col, time_col, target_col, X_df, level, quantiles, finetune_steps, finetune_loss, clean_ex_first, validate_api_key, add_history, date_features, date_features_to_one_hot, model, num_partitions)\u001b[0m\n\u001b[0;32m    966\u001b[0m nixtla_client_model \u001b[38;5;241m=\u001b[39m _NixtlaClientModel(\n\u001b[0;32m    967\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient,\n\u001b[0;32m    968\u001b[0m     h\u001b[38;5;241m=\u001b[39mh,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    983\u001b[0m     max_wait_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_wait_time,\n\u001b[0;32m    984\u001b[0m )\n\u001b[0;32m    985\u001b[0m df, X_df, uids_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uids_to_categorical(\n\u001b[0;32m    986\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf, X_df\u001b[38;5;241m=\u001b[39mX_df, id_col\u001b[38;5;241m=\u001b[39mid_col\n\u001b[0;32m    987\u001b[0m )\n\u001b[1;32m--> 988\u001b[0m fcst_df \u001b[38;5;241m=\u001b[39m \u001b[43mnixtla_client_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_history\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m fcst_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restore_uids(fcst_df, dtype\u001b[38;5;241m=\u001b[39muids_dtype, id_col\u001b[38;5;241m=\u001b[39mid_col)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_x \u001b[38;5;241m=\u001b[39m nixtla_client_model\u001b[38;5;241m.\u001b[39mweights_x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:587\u001b[0m, in \u001b[0;36m_NixtlaClientModel.forecast\u001b[1;34m(self, df, X_df, add_history)\u001b[0m\n\u001b[0;32m    585\u001b[0m     Y_df \u001b[38;5;241m=\u001b[39m Y_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtail(new_input_size)\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinetune_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_input_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m y, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframes_to_dict(Y_df, X_df)\n\u001b[0;32m    589\u001b[0m main_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling Forecast Endpoint...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtla\\nixtla_client.py:538\u001b[0m, in \u001b[0;36m_NixtlaClientModel.validate_input_size\u001b[1;34m(self, Y_df)\u001b[0m\n\u001b[0;32m    536\u001b[0m min_history \u001b[38;5;241m=\u001b[39m Y_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_history \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_horizon:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour time series data is too short \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease be sure that your unique time series contain \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_horizon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m observations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     )\n",
      "\u001b[1;31mException\u001b[0m: Your time series data is too short Please be sure that your unique time series contain at least 64 observations"
     ]
    }
   ],
   "source": [
    "from modules.models import arima_hybrid\n",
    "\n",
    "pr = arima_hybrid.get_arima_timegpt_predictions(data=a, prediction_horizon=1, frequency=\"weekly\", error_train_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3, -3, -3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1, 2, 3]) - np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from modules.data import data_loader\n",
    "\n",
    "a = data_loader.get_data(type = \"index\", ticker = \"NASDAQ Composite\", frequency = \"monthly\", start = \"1920-01-01\", end = \"2024-01-01\", rtrn = False)\n",
    "#a = data_loader.get_data(type = \"stock\", ticker = \"IBM\", frequency = \"daily\", start = \"01-01-2023\", end = \"01-01-2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\topco\\Dokumenti\\MSc Banking and Digital Finance UCL\\Modules\\Dissertation\\MSc_dissertation\\modules\\data\\data_loader.py:123: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['y'] = df['y'].fillna(method='bfill') # imputing the missing values\n"
     ]
    }
   ],
   "source": [
    "x = data_loader.get_exogenous_data(start_date=\"1920-01-01\", end_date=\"2024-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-01-01</td>\n",
       "      <td>0.274474</td>\n",
       "      <td>7.82</td>\n",
       "      <td>22.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-02-01</td>\n",
       "      <td>-0.273723</td>\n",
       "      <td>7.69</td>\n",
       "      <td>15.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>-0.457457</td>\n",
       "      <td>7.24</td>\n",
       "      <td>12.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-04-01</td>\n",
       "      <td>-0.183824</td>\n",
       "      <td>6.60</td>\n",
       "      <td>12.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-05-01</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>6.65</td>\n",
       "      <td>15.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0.436716</td>\n",
       "      <td>5.44</td>\n",
       "      <td>81.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>0.248513</td>\n",
       "      <td>5.49</td>\n",
       "      <td>89.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>-0.038338</td>\n",
       "      <td>5.46</td>\n",
       "      <td>85.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>-0.201514</td>\n",
       "      <td>5.41</td>\n",
       "      <td>77.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>-0.099332</td>\n",
       "      <td>5.32</td>\n",
       "      <td>71.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds        x1    x2     x3\n",
       "0   1986-01-01  0.274474  7.82  22.93\n",
       "1   1986-02-01 -0.273723  7.69  15.46\n",
       "2   1986-03-01 -0.457457  7.24  12.61\n",
       "3   1986-04-01 -0.183824  6.60  12.84\n",
       "4   1986-05-01  0.276243  6.65  15.38\n",
       "..         ...       ...   ...    ...\n",
       "451 2023-08-01  0.436716  5.44  81.39\n",
       "452 2023-09-01  0.248513  5.49  89.43\n",
       "453 2023-10-01 -0.038338  5.46  85.64\n",
       "454 2023-11-01 -0.201514  5.41  77.69\n",
       "455 2023-12-01 -0.099332  5.32  71.90\n",
       "\n",
       "[456 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985-01-01</td>\n",
       "      <td>278.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985-02-01</td>\n",
       "      <td>284.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985-03-01</td>\n",
       "      <td>279.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985-04-01</td>\n",
       "      <td>280.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985-05-01</td>\n",
       "      <td>290.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>14034.969727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>13219.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>12851.240234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>14226.219727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>15011.349609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds             y\n",
       "0   1985-01-01    278.700012\n",
       "1   1985-02-01    284.200012\n",
       "2   1985-03-01    279.200012\n",
       "3   1985-04-01    280.600006\n",
       "4   1985-05-01    290.799988\n",
       "..         ...           ...\n",
       "463 2023-08-01  14034.969727\n",
       "464 2023-09-01  13219.320312\n",
       "465 2023-10-01  12851.240234\n",
       "466 2023-11-01  14226.219727\n",
       "467 2023-12-01  15011.349609\n",
       "\n",
       "[468 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "\n",
    "# this is for renaming files\n",
    "\n",
    "def rename_files_in_folder(folder_path, old_string, new_string):\n",
    "    try:\n",
    "        # Get the list of all files in the specified folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        for filename in files:\n",
    "            # Check if the old string is in the filename\n",
    "            if old_string in filename:\n",
    "                # Create the new filename by replacing the old string with the new string\n",
    "                new_filename = filename.replace(old_string, new_string)\n",
    "                \n",
    "                # Construct the full file paths\n",
    "                old_file_path = os.path.join(folder_path, filename)\n",
    "                new_file_path = os.path.join(folder_path, new_filename)\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                \n",
    "                print(f\"Renamed: {filename} -> {new_filename}\")\n",
    "            else:\n",
    "                print(f\"No match found in: {filename}\")\n",
    "                \n",
    "        print(\"Renaming process completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "folder_path = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"prediction\")) #\"/results/evaluation\"\n",
    "folder_path_2 = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"evaluation\"))\n",
    "\n",
    "s1 = \"TSCV_R\"\n",
    "s2 = \"TSCVR\"\n",
    "\n",
    "rename_files_in_folder(folder_path, s1, s2)\n",
    "rename_files_in_folder(folder_path_2, s1, s2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming process completed.\n",
      "Renaming process completed.\n"
     ]
    }
   ],
   "source": [
    "'''# this is for adding something at the end\n",
    "\n",
    "import os\n",
    "\n",
    "# this is for renaming files\n",
    "\n",
    "def rename_files_in_folder(folder_path):\n",
    "    try:\n",
    "        # Get the list of all files in the specified folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        for filename in files:\n",
    "            # Check if the old string is in the filename\n",
    "            \n",
    "                old_file_path = os.path.join(folder_path, filename)\n",
    "                new_file_path = old_file_path[:-4] + \"__BS=5__ME=4.csv\"\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                \n",
    "                \n",
    "                \n",
    "        print(\"Renaming process completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "folder_path = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"prediction\")) #\"/results/evaluation\"\n",
    "folder_path_2 = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"evaluation\"))\n",
    "\n",
    "\n",
    "\n",
    "rename_files_in_folder(folder_path)\n",
    "rename_files_in_folder(folder_path_2)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "#constraint: FOLDS x PREDICTION_LENGTH + TRAIN_SIZE !!must not!! be bigger than len(data)\n",
    "\n",
    "PREDICTION_LENGTH = 1 # currentlz only works for PREDICTION_LENGTH > 1\n",
    "TICKER = \"S&P 500\"\n",
    "FREQUENCY = \"minutely\" # currently we only have dailz frequency\n",
    "TYPE_OF_DATA = \"stock\" # currently we only have stock prices saved\n",
    "MODELS = [\"arima\", \"llama\", \"autoregressor\", \"fine-tuned Llama\"] # currentlz works onlz for these two\n",
    "FOLDS = 5 # for TSCV # reduced to two for testing purposes\n",
    "CONTEXT_LENGTH = 245 # set to 245 for testing purposes\n",
    "METRICS = ['r2', 'mse', 'mae', 'rmse', 'mda', \"mape\"]\n",
    "\n",
    "# fine-tuning parameters\n",
    "BATCH_SIZE = 10\n",
    "MAX_EPOCHS = 5\n",
    "\n",
    "# data parameters\n",
    "START_DATE = \"2024-07-22\"\n",
    "END_DATE = \"2024-07-23\"\n",
    "\n",
    "# want to add\n",
    "#TRAIN_PERIOD = # context lenghts. Should take a look into this\n",
    "TRAIN_SIZE = CONTEXT_LENGTH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY)\n",
    "# this is just in case there are more CSVs of the same type and frequency, the data should be the first in the list\n",
    "#if len(data) > 1:\n",
    "data = data[0]\n",
    "\n",
    "simple_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"simple\"])\n",
    "#if len(simple_data) > 1:\n",
    "simple_data = simple_data[0]\n",
    "\n",
    "train_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"train\"])\n",
    "train_data = train_data[0]\n",
    "\n",
    "test_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"test\"])\n",
    "test_data = test_data[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CONFIG = {\"ticker\" : TICKER,\n",
    "               \"frequency\" : FREQUENCY,\n",
    "               \"start\" : START_DATE,\n",
    "               \"end\" : END_DATE}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loader.get_data(data_type=TYPE_OF_DATA, kwargs=DATA_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LENGTH = len(data)\n",
    "FOLDS = int((DATA_LENGTH - TRAIN_SIZE) / PREDICTION_LENGTH) # this calculates max ammount of folds we can have given a set TRAIN_SIZE and PREDICTION_LENGTH\n",
    "FOLDS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"ticker\" : \"USD/GBP\",\n",
    "          \"frequency\" : \"daily\",\n",
    "          \"start\" : \"2024-07-01\",\n",
    "          \"end\" : \"2024-07-30\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getenv(\"ALPHAVANTAGE_API\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"ALPHAVANTAGE_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in os.environ.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = data_loader.get_data(data_type=\"exchange_rate\", kwargs=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY,\n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"PREDICTION_LENGTH={PREDICTION_LENGTH}__TICKER={TICKER}__FREQUENCY={FREQUENCY}__TYPE_OF_DATA={TYPE_OF_DATA}__FOLDS={FOLDS}__CONTEXT_LENGTH/TRAIN_SIZE={CONTEXT_LENGTH}__FT_START_DATE={FT_START_DATE}__START_DATE={START_DATE}__END_DATE={END_DATE}__FT_LENGTH={FT_LENGTH}__DATA_LENGTH={DATA_LENGTH}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"P_L={PREDICTION_LENGTH}__T={TICKER}__FR={FREQUENCY}__T_O_D={TYPE_OF_DATA}__FO={FOLDS}__C_L_T_S={CONTEXT_LENGTH}__FT_S_D={FT_START_DATE}__S_D={START_DATE}__E_D={END_DATE}__FT_L={FT_LENGTH}__D_L={DATA_LENGTH}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_saver.save_results(r, experiment_name, type=\"evaluation\")\n",
    "result_saver.save_results(p, experiment_name, type=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p, a = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY, \n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the summary for each model\n",
    "s = [get_summary(r[i]) for i in range(len(r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df, medians_df, stds_df = extract_metrics(s, MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.standard_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.interactive_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.prediction_visualisation(MODELS, p, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEL the graph\n",
    "label the axes with timestamps\n",
    "show the history of the actual\n",
    "table of comparison, not just graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
