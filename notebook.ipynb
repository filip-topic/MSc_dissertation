{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import  data_reader, data_loader\n",
    "from modules.sr import result_saver\n",
    "from modules.models import lag_llama\n",
    "from modules.experiment.tscv import get_tscv_results, get_summary, extract_metrics\n",
    "from modules.visualization import graphs\n",
    "from modules.fine_tuning import lag_llama_ft\n",
    "from modules.models import prpht\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_loader\n",
    "\n",
    "a = data_loader.get_data(type = \"fx\", ticker = \"USD/GBP\", frequency = \"weekly\", start = \"2019-01-01\", end = \"2024-01-01\", rtrn = True)\n",
    "#a = data_loader.get_data(type = \"stock\", ticker = \"IBM\", frequency = \"daily\", start = \"01-01-2023\", end = \"01-01-2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtlats\\__init__.py:5: FutureWarning: This package is deprecated, please install nixtla instead.\n",
      "  warnings.warn(\"This package is deprecated, please install nixtla instead.\", category=FutureWarning)\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: W-SUN\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n"
     ]
    }
   ],
   "source": [
    "from modules.models import timegpt\n",
    "pr = timegpt.get_timegpt_forecast(data=a, prediction_length=1, frequency=\"weekly\", ft_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.002209331840276718]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Error Message': 'Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_INTRADAY.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "api = os.getenv(\"ALPHAVANTAGE_API\")\n",
    "\n",
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=NATURAL_GAS&interval=1min&apikey={api}&month=2019-01-01'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to 'c:\\Users\\topco\\Dokumenti\\MSc Banking and Digital Finance UCL\\Modules\\Dissertation\\MSc_dissertation\\results\\evaluation\\test'.\n"
     ]
    }
   ],
   "source": [
    "from modules.sr import result_saver\n",
    "\n",
    "result_saver.save_results(a, \"test\", type=\"evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is for renaming files\n",
    "\n",
    "def rename_files_in_folder(folder_path, old_string, new_string):\n",
    "    try:\n",
    "        # Get the list of all files in the specified folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        for filename in files:\n",
    "            # Check if the old string is in the filename\n",
    "            if old_string in filename:\n",
    "                # Create the new filename by replacing the old string with the new string\n",
    "                new_filename = filename.replace(old_string, new_string)\n",
    "                \n",
    "                # Construct the full file paths\n",
    "                old_file_path = os.path.join(folder_path, filename)\n",
    "                new_file_path = os.path.join(folder_path, new_filename)\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                \n",
    "                print(f\"Renamed: {filename} -> {new_filename}\")\n",
    "            else:\n",
    "                print(f\"No match found in: {filename}\")\n",
    "                \n",
    "        print(\"Renaming process completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "folder_path = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"prediction\")) #\"/results/evaluation\"\n",
    "folder_path_2 = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"evaluation\"))\n",
    "\n",
    "s1 = \"TSCV_R\"\n",
    "s2 = \"TSCVR\"\n",
    "\n",
    "rename_files_in_folder(folder_path, s1, s2)\n",
    "rename_files_in_folder(folder_path_2, s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming process completed.\n",
      "Renaming process completed.\n"
     ]
    }
   ],
   "source": [
    "# this is for adding something at the end\n",
    "\n",
    "import os\n",
    "\n",
    "# this is for renaming files\n",
    "\n",
    "def rename_files_in_folder(folder_path):\n",
    "    try:\n",
    "        # Get the list of all files in the specified folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        for filename in files:\n",
    "            # Check if the old string is in the filename\n",
    "            \n",
    "                old_file_path = os.path.join(folder_path, filename)\n",
    "                new_file_path = old_file_path[:-4] + \"__BS=5__ME=4.csv\"\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                \n",
    "                \n",
    "                \n",
    "        print(\"Renaming process completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "folder_path = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"prediction\")) #\"/results/evaluation\"\n",
    "folder_path_2 = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"evaluation\"))\n",
    "\n",
    "\n",
    "\n",
    "rename_files_in_folder(folder_path)\n",
    "rename_files_in_folder(folder_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_reader\n",
    "import pandas as pd\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "a = data_reader.read_data([\"\"], \"data/interest_rate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\topco\\Dokumenti\\MSc Banking and Digital Finance UCL\\Modules\\Dissertation\\MSc_dissertation\\modules\\data\\data_loader.py:123: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['y'] = df['y'].fillna(method='bfill') # imputing the missing values\n"
     ]
    }
   ],
   "source": [
    "from modules.data import data_loader, data_reader\n",
    "import pandas as pd\n",
    "start_date = \"2019-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "\n",
    "x_df = data_loader.get_exogenous_data(start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from modules.data import data_loader\n",
    "\n",
    "data = data_loader.get_data(type = \"index\", ticker = \"S&P 500\", frequency = \"monthly\", start = \"2019-01-01\", end = \"2024-01-01\", rtrn = True)\n",
    "#a = data_loader.get_data(type = \"stock\", ticker = \"IBM\", frequency = \"daily\", start = \"01-01-2023\", end = \"01-01-2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\nixtlats\\__init__.py:5: FutureWarning: This package is deprecated, please install nixtla instead.\n",
      "  warnings.warn(\"This package is deprecated, please install nixtla instead.\", category=FutureWarning)\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n",
      "INFO:nixtla.nixtla_client:Restricting input...\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n",
      "INFO:nixtla.nixtla_client:Restricting input...\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n",
      "INFO:nixtla.nixtla_client:Restricting input...\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n",
      "INFO:nixtla.nixtla_client:Using the following exogenous variables: x1, x2, x3\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n"
     ]
    }
   ],
   "source": [
    "from modules.models import timegpt\n",
    "pr = timegpt.get_timegpt_forecast(data=data, prediction_length=1, frequency=\"monthly\", ft_steps=10, x=x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009347334659264498]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Inferred freq: MS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Restricting input...\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2024-01-01\n",
       "Name: ds, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nixtlats import TimeGPT\n",
    "from nixtla import NixtlaClient\n",
    "\n",
    "nixtla_client = NixtlaClient(\n",
    "    #api_key=os.getenv(\"NIXTLA_API\")\n",
    "    api_key = \"nixtla-tok-co7tFFNHZUZfr0Q1FS7VlWmnzoZpWD3x0eVwRx6U3gCUWOoYkpMSf3BJC9fySpa96kb3QdDUPdIpPE9V\"\n",
    ")\n",
    "\n",
    "nixtla_client.forecast(df = data, h = 1, freq = \"M\", time_col=\"ds\", target_col=\"y\")[\"ds\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "#constraint: FOLDS x PREDICTION_LENGTH + TRAIN_SIZE !!must not!! be bigger than len(data)\n",
    "\n",
    "PREDICTION_LENGTH = 1 # currentlz only works for PREDICTION_LENGTH > 1\n",
    "TICKER = \"S&P 500\"\n",
    "FREQUENCY = \"minutely\" # currently we only have dailz frequency\n",
    "TYPE_OF_DATA = \"stock\" # currently we only have stock prices saved\n",
    "MODELS = [\"arima\", \"llama\", \"autoregressor\", \"fine-tuned Llama\"] # currentlz works onlz for these two\n",
    "FOLDS = 5 # for TSCV # reduced to two for testing purposes\n",
    "CONTEXT_LENGTH = 245 # set to 245 for testing purposes\n",
    "METRICS = ['r2', 'mse', 'mae', 'rmse', 'mda', \"mape\"]\n",
    "\n",
    "# fine-tuning parameters\n",
    "BATCH_SIZE = 10\n",
    "MAX_EPOCHS = 5\n",
    "\n",
    "# data parameters\n",
    "START_DATE = \"2024-07-22\"\n",
    "END_DATE = \"2024-07-23\"\n",
    "\n",
    "# want to add\n",
    "#TRAIN_PERIOD = # context lenghts. Should take a look into this\n",
    "TRAIN_SIZE = CONTEXT_LENGTH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY)\n",
    "# this is just in case there are more CSVs of the same type and frequency, the data should be the first in the list\n",
    "#if len(data) > 1:\n",
    "data = data[0]\n",
    "\n",
    "simple_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"simple\"])\n",
    "#if len(simple_data) > 1:\n",
    "simple_data = simple_data[0]\n",
    "\n",
    "train_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"train\"])\n",
    "train_data = train_data[0]\n",
    "\n",
    "test_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"test\"])\n",
    "test_data = test_data[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CONFIG = {\"ticker\" : TICKER,\n",
    "               \"frequency\" : FREQUENCY,\n",
    "               \"start\" : START_DATE,\n",
    "               \"end\" : END_DATE}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loader.get_data(data_type=TYPE_OF_DATA, kwargs=DATA_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LENGTH = len(data)\n",
    "FOLDS = int((DATA_LENGTH - TRAIN_SIZE) / PREDICTION_LENGTH) # this calculates max ammount of folds we can have given a set TRAIN_SIZE and PREDICTION_LENGTH\n",
    "FOLDS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"ticker\" : \"USD/GBP\",\n",
    "          \"frequency\" : \"daily\",\n",
    "          \"start\" : \"2024-07-01\",\n",
    "          \"end\" : \"2024-07-30\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getenv(\"ALPHAVANTAGE_API\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"ALPHAVANTAGE_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in os.environ.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = data_loader.get_data(data_type=\"exchange_rate\", kwargs=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY,\n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"PREDICTION_LENGTH={PREDICTION_LENGTH}__TICKER={TICKER}__FREQUENCY={FREQUENCY}__TYPE_OF_DATA={TYPE_OF_DATA}__FOLDS={FOLDS}__CONTEXT_LENGTH/TRAIN_SIZE={CONTEXT_LENGTH}__FT_START_DATE={FT_START_DATE}__START_DATE={START_DATE}__END_DATE={END_DATE}__FT_LENGTH={FT_LENGTH}__DATA_LENGTH={DATA_LENGTH}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"P_L={PREDICTION_LENGTH}__T={TICKER}__FR={FREQUENCY}__T_O_D={TYPE_OF_DATA}__FO={FOLDS}__C_L_T_S={CONTEXT_LENGTH}__FT_S_D={FT_START_DATE}__S_D={START_DATE}__E_D={END_DATE}__FT_L={FT_LENGTH}__D_L={DATA_LENGTH}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_saver.save_results(r, experiment_name, type=\"evaluation\")\n",
    "result_saver.save_results(p, experiment_name, type=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p, a = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY, \n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the summary for each model\n",
    "s = [get_summary(r[i]) for i in range(len(r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df, medians_df, stds_df = extract_metrics(s, MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.standard_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.interactive_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.prediction_visualisation(MODELS, p, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEL the graph\n",
    "label the axes with timestamps\n",
    "show the history of the actual\n",
    "table of comparison, not just graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
