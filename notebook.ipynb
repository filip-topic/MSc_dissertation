{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import  data_reader, data_loader\n",
    "from modules.sr import result_saver\n",
    "from modules.models import lag_llama\n",
    "from modules.experiment.tscv import get_tscv_results, get_summary, extract_metrics\n",
    "from modules.visualization import graphs\n",
    "from modules.fine_tuning import lag_llama_ft\n",
    "from modules.models import prpht\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earliest monthly data for S&P500 is 1985\n",
    "FTSE 100 also 1985\n",
    "NASDAQ also 1985\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from modules.data import data_loader\n",
    "\n",
    "a = data_loader.get_data(type = \"index\", ticker=\"S&P 500\", frequency = \"weekly\", start = \"2017-01-01\", end = \"2022-01-01\", rtrn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>-0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>-0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>0.010294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-02-05</td>\n",
       "      <td>0.008131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>0.038442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2020-10-11</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2020-10-18</td>\n",
       "      <td>-0.005287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>-0.056395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.073236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y\n",
       "1   2017-01-08 -0.001028\n",
       "2   2017-01-15 -0.001464\n",
       "3   2017-01-22  0.010294\n",
       "4   2017-01-29  0.001190\n",
       "5   2017-02-05  0.008131\n",
       "..         ...       ...\n",
       "196 2020-10-04  0.038442\n",
       "197 2020-10-11  0.001918\n",
       "198 2020-10-18 -0.005287\n",
       "199 2020-10-25 -0.056395\n",
       "200 2020-11-01  0.073236\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = data_loader.get_data(type = \"cc\", frequency = \"weekly\", ticker = \"Social\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_loader.get_data(type = \"fx\", ticker = \"USD/GBP\", frequency = \"daily\", rtrn = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc[\"Date\", \"Aggregate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_loader\n",
    "\n",
    "a = data_loader.get_data(type = \"index\",ticker=\"NASDAQ\", frequency = \"daily\", start = \"2022-01-01\", end = \"2024-01-01\", rtrn = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data_loader.get_data(type = \"index\",ticker=\"S&P 500\", frequency = \"daily\", start = \"2022-01-01\", end = \"2024-01-01\", rtrn = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import arima_hybrid\n",
    "\n",
    "pr = arima_hybrid.get_arima_timegpt_predictions(data=a, prediction_horizon=1, frequency=\"daily\", error_train_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array([1, 2, 3]) - np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_loader\n",
    "\n",
    "a = data_loader.get_data(type = \"index\", ticker = \"NASDAQ Composite\", frequency = \"monthly\", start = \"1920-01-01\", end = \"2024-01-01\", rtrn = False)\n",
    "#a = data_loader.get_data(type = \"stock\", ticker = \"IBM\", frequency = \"daily\", start = \"01-01-2023\", end = \"01-01-2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_loader.get_exogenous_data(start_date=\"1920-01-01\", end_date=\"2024-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "pd.read_csv(os.path.join(\"data\", \"credit_card\", \"uk_credit_card_data_monthly.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# this is for renaming files\n",
    "\n",
    "#import os\n",
    "'''def rename_files_in_folder(folder_path, old_string, new_string):\n",
    "    try:\n",
    "        # Get the list of all files in the specified folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        for filename in files:\n",
    "            # Check if the old string is in the filename\n",
    "            if old_string in filename:\n",
    "                # Create the new filename by replacing the old string with the new string\n",
    "                new_filename = filename.replace(old_string, new_string)\n",
    "                \n",
    "                # Construct the full file paths\n",
    "                old_file_path = os.path.join(folder_path, filename)\n",
    "                new_file_path = os.path.join(folder_path, new_filename)\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                \n",
    "                print(f\"Renamed: {filename} -> {new_filename}\")\n",
    "            else:\n",
    "                print(f\"No match found in: {filename}\")\n",
    "                \n",
    "        print(\"Renaming process completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "folder_path = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"partial\", \"prediction\")) #\"/results/evaluation\"\n",
    "folder_path_2 = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"partial\", \"evaluation\"))\n",
    "\n",
    "s1 = \"__\"\n",
    "s2 = \"_\"\n",
    "\n",
    "rename_files_in_folder(folder_path, s1, s2)\n",
    "rename_files_in_folder(folder_path_2, s1, s2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for adding something at the end\n",
    "\n",
    "'''import os\n",
    "\n",
    "# this is for renaming files\n",
    "\n",
    "def rename_files_in_folder(folder_path):\n",
    "    try:\n",
    "        # Get the list of all files in the specified folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        for filename in files:\n",
    "            # Check if the old string is in the filename\n",
    "            \n",
    "                old_file_path = os.path.join(folder_path, filename)\n",
    "                new_file_path = old_file_path[:-4] + \"__BS=5__ME=4.csv\"\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                \n",
    "                \n",
    "                \n",
    "        print(\"Renaming process completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "folder_path = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"partial\", \"prediction\")) #\"/results/evaluation\"\n",
    "folder_path_2 = os.path.abspath(os.path.join(os.getcwd(), \"results\", \"partial\", \"evaluation\"))\n",
    "\n",
    "\n",
    "\n",
    "rename_files_in_folder(folder_path)\n",
    "rename_files_in_folder(folder_path_2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this combines ft_timeGPT evaluation with previous results\n",
    "\n",
    "'''import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the folders\n",
    "folder1 = \"results/prediction\"\n",
    "folder2 = \"results/partial/prediction\"\n",
    "\n",
    "# Get a list of all .csv files in both folders\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith('.csv')]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith('.csv')]\n",
    "\n",
    "# Ensure that only matching files are processed\n",
    "matching_files = set(files1) & set(files2)\n",
    "\n",
    "# Loop through each matching file\n",
    "for filename in matching_files:\n",
    "    # Construct the full file paths\n",
    "    file1_path = os.path.join(folder1, filename)\n",
    "    file2_path = os.path.join(folder2, filename)\n",
    "    \n",
    "    # Read the dataframes from both files\n",
    "    df1 = pd.read_csv(file1_path, index_col=0)\n",
    "    df2 = pd.read_csv(file2_path, index_col=0)\n",
    "    \n",
    "    # Concatenate the dataframes, preserving the index\n",
    "    combined_df = pd.merge(df1, df2, on=['actual', 'timestamp'])\n",
    "    \n",
    "    # Save the combined dataframe back to the file in the first folder\n",
    "    combined_df.to_csv(file1_path)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "#constraint: FOLDS x PREDICTION_LENGTH + TRAIN_SIZE !!must not!! be bigger than len(data)\n",
    "\n",
    "PREDICTION_LENGTH = 1 # currentlz only works for PREDICTION_LENGTH > 1\n",
    "TICKER = \"S&P 500\"\n",
    "FREQUENCY = \"minutely\" # currently we only have dailz frequency\n",
    "TYPE_OF_DATA = \"stock\" # currently we only have stock prices saved\n",
    "MODELS = [\"arima\", \"llama\", \"autoregressor\", \"fine-tuned Llama\"] # currentlz works onlz for these two\n",
    "FOLDS = 5 # for TSCV # reduced to two for testing purposes\n",
    "CONTEXT_LENGTH = 245 # set to 245 for testing purposes\n",
    "METRICS = ['r2', 'mse', 'mae', 'rmse', 'mda', \"mape\"]\n",
    "\n",
    "# fine-tuning parameters\n",
    "BATCH_SIZE = 10\n",
    "MAX_EPOCHS = 5\n",
    "\n",
    "# data parameters\n",
    "START_DATE = \"2024-07-22\"\n",
    "END_DATE = \"2024-07-23\"\n",
    "\n",
    "# want to add\n",
    "#TRAIN_PERIOD = # context lenghts. Should take a look into this\n",
    "TRAIN_SIZE = CONTEXT_LENGTH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY)\n",
    "# this is just in case there are more CSVs of the same type and frequency, the data should be the first in the list\n",
    "#if len(data) > 1:\n",
    "data = data[0]\n",
    "\n",
    "simple_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"simple\"])\n",
    "#if len(simple_data) > 1:\n",
    "simple_data = simple_data[0]\n",
    "\n",
    "train_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"train\"])\n",
    "train_data = train_data[0]\n",
    "\n",
    "test_data = data_reader.read_data(type = TYPE_OF_DATA, frequency = FREQUENCY, match = [\"test\"])\n",
    "test_data = test_data[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CONFIG = {\"ticker\" : TICKER,\n",
    "               \"frequency\" : FREQUENCY,\n",
    "               \"start\" : START_DATE,\n",
    "               \"end\" : END_DATE}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loader.get_data(data_type=TYPE_OF_DATA, kwargs=DATA_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LENGTH = len(data)\n",
    "FOLDS = int((DATA_LENGTH - TRAIN_SIZE) / PREDICTION_LENGTH) # this calculates max ammount of folds we can have given a set TRAIN_SIZE and PREDICTION_LENGTH\n",
    "FOLDS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"ticker\" : \"USD/GBP\",\n",
    "          \"frequency\" : \"daily\",\n",
    "          \"start\" : \"2024-07-01\",\n",
    "          \"end\" : \"2024-07-30\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getenv(\"ALPHAVANTAGE_API\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"ALPHAVANTAGE_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in os.environ.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = data_loader.get_data(data_type=\"exchange_rate\", kwargs=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY,\n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"PREDICTION_LENGTH={PREDICTION_LENGTH}__TICKER={TICKER}__FREQUENCY={FREQUENCY}__TYPE_OF_DATA={TYPE_OF_DATA}__FOLDS={FOLDS}__CONTEXT_LENGTH/TRAIN_SIZE={CONTEXT_LENGTH}__FT_START_DATE={FT_START_DATE}__START_DATE={START_DATE}__END_DATE={END_DATE}__FT_LENGTH={FT_LENGTH}__DATA_LENGTH={DATA_LENGTH}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"P_L={PREDICTION_LENGTH}__T={TICKER}__FR={FREQUENCY}__T_O_D={TYPE_OF_DATA}__FO={FOLDS}__C_L_T_S={CONTEXT_LENGTH}__FT_S_D={FT_START_DATE}__S_D={START_DATE}__E_D={END_DATE}__FT_L={FT_LENGTH}__D_L={DATA_LENGTH}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_saver.save_results(r, experiment_name, type=\"evaluation\")\n",
    "result_saver.save_results(p, experiment_name, type=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the training data for lag llama fine tuning\n",
    "ft_train_data = lag_llama.prepare_data(data=ft_data, \n",
    "                                       prediction_length=0, \n",
    "                                       frequency=FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the lag llama predictor object \n",
    "predictor = lag_llama_ft.get_predictor(prediction_length=PREDICTION_LENGTH, \n",
    "                                       context_length=CONTEXT_LENGTH, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       max_epochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the predictor object\n",
    "predictor = predictor.train(ft_train_data, \n",
    "                            cache_data = True, \n",
    "                            shuffle_buffer_length = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p, a = get_tscv_results(data = data,\n",
    "                           prediction_horizon=PREDICTION_LENGTH,\n",
    "                           context_length=CONTEXT_LENGTH, \n",
    "                           folds=FOLDS, \n",
    "                           frequency=FREQUENCY, \n",
    "                           predictor=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the summary for each model\n",
    "s = [get_summary(r[i]) for i in range(len(r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df, medians_df, stds_df = extract_metrics(s, MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.standard_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.interactive_visualisation(MODELS, METRICS, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.prediction_visualisation(MODELS, p, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEL the graph\n",
    "label the axes with timestamps\n",
    "show the history of the actual\n",
    "table of comparison, not just graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
