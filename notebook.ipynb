{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import data_loader, data_splitter, data_reader\n",
    "from modules.models import arima, lag_llama\n",
    "from modules.evaluation import evaluate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from modules.experiment.experiment import run_experiment\n",
    "from modules.data.tscv import create_tscv_dataset\n",
    "from modules.experiment.tscv import get_tscv_results, mean_directional_accuracy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_LENGTH = 10 # currentlz only works for PREDICTION_LENGTH > 1\n",
    "FREQUENCY = \"daily\" # currently we only have dailz frequency\n",
    "TYPE_OF_DATA = \"stock\" # currently we only have stock prices saved\n",
    "MODELS = [\"arima\", \"llama\"] # currentlz works onlz for these two\n",
    "\n",
    "# want to add\n",
    "PREDICTION_HORIZON = 3 # can use anything as long as it complies with data length\n",
    "#TRAIN_PERIOD = # context lenghts. Should take a look into this\n",
    "#TRAIN_SIZE = \n",
    "FOLDS = 10# for TSCV\n",
    "CONTEXT_LENGTH = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series1 = pd.Series([1, 2, 3])\n",
    "series2 = pd.Series([5,6, 3])\n",
    "\n",
    "mean_directional_accuracy(series1, series2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - autoregressor\n",
    " - mean directional accuracy\n",
    " - ask\n",
    " - for each time-series create a whole dataframe for TSCV\n",
    "  - problem with this is with time horizon that is >1 \n",
    "  - prediction horizon is only for that value in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - create the TSCV experiment. It needs to create a table. Metrics for each fold\n",
    " - lit review\n",
    " - content for the presentation by monday!!\n",
    " - review data leakage risk\n",
    " - writing of the dissertation\n",
    " - autoregressor\n",
    " - MDA metric\n",
    " - frequency\n",
    "\n",
    " Writing\n",
    " - lit review\n",
    " - lit reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# loading the data for all 500 S&P500 stocks\n",
    "data = data_reader.read_data(TYPE_OF_DATA)[0]\n",
    "simple_data = data_loader.get_simle_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass full data at maximum granularity and produce according to frequency parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv_data = create_tscv_dataset(data = simple_data, context_length=CONTEXT_LENGTH, n_folds=FOLDS, prediction_horizon=PREDICTION_HORIZON, max_folds=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run regular experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiment(data = data, prediction_length = PREDICTION_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TSCV experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look up tzpes of TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0 done  1\n",
      "------------\n",
      "y1 done  2\n",
      "------------\n",
      "y2 done  3\n",
      "------------\n",
      "y3 done  4\n",
      "------------\n",
      "y4 done  5\n",
      "------------\n",
      "y5 done  6\n",
      "------------\n",
      "y6 done  7\n",
      "------------\n",
      "y7 done  8\n",
      "------------\n",
      "y8 done  9\n",
      "------------\n",
      "y9 done  10\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "tscv_results, prediction = run_experiment(data=tscv_data, tscv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': {'arima': -0.8036159605688358, 'llama': -4.690321882253741},\n",
       " 'mse': {'arima': 9.014638013311012, 'llama': 28.440750730306206},\n",
       " 'mae': {'arima': 2.712121007999187, 'llama': 4.178632465124013},\n",
       " 'rmse': {'arima': 3.0024386776936867, 'llama': 5.332987036390226}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "simple_data = data_loader.get_simle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn tscv object\n",
    "tscv = TimeSeriesSplit(n_splits=FOLDS, test_size=PREDICTION_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the time-series data from original data\n",
    "series = simple_data[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- put metrics in dataframe. one for arima, one for lag llama\n",
    "- each column metric, each row is a fold\n",
    "- create wrapper function get_metrics(predicted, actual) returns pd.DataFrame of description above\n",
    "- by end of day have a table\n",
    "- agenda of the presentation by 12\n",
    "- implement autoregressor forecast t1 = t0\n",
    "- implement frequency experimentation\n",
    "- start training date global parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-9.88214173756848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Local\\Temp\\ipykernel_18956\\3132376272.py:73: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  arima_results = pd.concat([arima_results, pd.DataFrame([arima_metrics], columns=metrics)], ignore_index=True)\n",
      "C:\\Users\\topco\\AppData\\Local\\Temp\\ipykernel_18956\\3132376272.py:74: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  llama_results = pd.concat([llama_results, pd.DataFrame([llama_metrics], columns=metrics)], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-7.331208574748089\n",
      "2\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-23.111337830449575\n",
      "3\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-105.08256584719334\n",
      "4\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-14.882898517829759\n",
      "5\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-1.7788387313339746\n",
      "6\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-5.033386216002038\n",
      "7\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-13.167825665726498\n",
      "8\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-7.01598773131259\n",
      "9\n",
      "----------\n",
      "10\n",
      "--------------\n",
      "10\n",
      "---------------\n",
      "10\n",
      "------------------\n",
      "-28.119125267629563\n"
     ]
    }
   ],
   "source": [
    "# initializing the list of models, metrics and emptz result dict\n",
    "models=[\"arima\", \"llama\"]\n",
    "metrics=[\"r2\", \"mse\", \"mae\", \"rmse\", \"mda\"]\n",
    "results = {metric: {model: {f\"fold_{i}\": [] for i in range(FOLDS)} for model in models} for metric in metrics}\n",
    "\n",
    "arima_results = pd.DataFrame(columns=metrics)\n",
    "\n",
    "llama_results = pd.DataFrame(columns= metrics)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "# iterating over all the folds\n",
    "for train_index, test_index in tscv.split(series):\n",
    "    # subsetting the original data according to train/test split\n",
    "    train = simple_data.iloc[train_index]\n",
    "    valid = list(simple_data.iloc[test_index][\"y\"])\n",
    "\n",
    "    # for my testing purposes\n",
    "    #print(train[\"y\"])\n",
    "    #print(train[\"y\"].iloc[-1])\n",
    "\n",
    "\n",
    "    # inputting data into the models\n",
    "    arima_model = arima.get_autoarima(train)\n",
    "    autoarima_predictions = arima.autoarima_predictions(arima_model, PREDICTION_LENGTH)\n",
    "    lag_llama_predictions, tss = lag_llama.get_lam_llama_forecast(train, PREDICTION_LENGTH, context_length=CONTEXT_LENGTH)\n",
    "    lag_llama_predictions = list(lag_llama_predictions[0].samples.mean(axis = 0))\n",
    "\n",
    "    \"\"\"\n",
    "    print(i)\n",
    "    print(\"----------\")\n",
    "    print(len(lag_llama_predictions))\n",
    "    print(\"--------------\")\n",
    "    print(len(valid))\n",
    "    print(\"---------------\")\n",
    "    print(PREDICTION_LENGTH)\n",
    "    print(\"------------------\")\n",
    "    print(r2_score(valid, lag_llama_predictions))\n",
    "    \"\"\"\n",
    "\n",
    "    # for my own testing purposes\n",
    "    \"\"\"\n",
    "    print(autoarima_predictions)\n",
    "    print(lag_llama_predictions)\n",
    "    print(valid)\n",
    "    \"\"\"\n",
    "\n",
    "    # recording the metrics\n",
    "    \"\"\"\n",
    "    results[\"r2\"][\"arima\"][f\"fold_{i}\"].append(r2_score(valid, autoarima_predictions))\n",
    "    results[\"mse\"][\"arima\"][f\"fold_{i}\"].append(mean_squared_error(valid, autoarima_predictions))\n",
    "    results[\"mae\"][\"arima\"][f\"fold_{i}\"].append(mean_absolute_error(valid, autoarima_predictions))\n",
    "    results[\"rmse\"][\"arima\"][f\"fold_{i}\"].append(np.sqrt(mean_squared_error(valid, autoarima_predictions)))\n",
    "\n",
    "    results[\"r2\"][\"llama\"][f\"fold_{i}\"].append(r2_score(valid, lag_llama_predictions))\n",
    "    results[\"mse\"][\"llama\"][f\"fold_{i}\"].append(mean_squared_error(valid, lag_llama_predictions))\n",
    "    results[\"mae\"][\"llama\"][f\"fold_{i}\"].append(mean_absolute_error(valid, lag_llama_predictions))\n",
    "    results[\"rmse\"][\"llama\"][f\"fold_{i}\"].append(np.sqrt(mean_squared_error(valid, lag_llama_predictions)))\n",
    "    \"\"\"\n",
    "\n",
    "    arima_metrics = [r2_score(valid, autoarima_predictions), \n",
    "               mean_squared_error(valid, autoarima_predictions), \n",
    "               mean_absolute_error(valid, autoarima_predictions),\n",
    "               np.sqrt(mean_squared_error(valid, autoarima_predictions)),\n",
    "               mean_directional_accuracy(valid, autoarima_predictions, train[\"y\"].iloc[-1])]\n",
    "    \n",
    "    llama_metrics = [r2_score(valid, lag_llama_predictions), \n",
    "               mean_squared_error(valid, lag_llama_predictions), \n",
    "               mean_absolute_error(valid, lag_llama_predictions),\n",
    "               np.sqrt(mean_squared_error(valid, lag_llama_predictions)),\n",
    "               mean_directional_accuracy(valid, lag_llama_predictions, train[\"y\"].iloc[-1])]\n",
    "\n",
    "    arima_results = pd.concat([arima_results, pd.DataFrame([arima_metrics], columns=metrics)], ignore_index=True)\n",
    "    llama_results = pd.concat([llama_results, pd.DataFrame([llama_metrics], columns=metrics)], ignore_index=True)\n",
    "\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.146053</td>\n",
       "      <td>33.415565</td>\n",
       "      <td>5.512960</td>\n",
       "      <td>5.780620</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.069529</td>\n",
       "      <td>56.237796</td>\n",
       "      <td>5.979982</td>\n",
       "      <td>7.499186</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.021127</td>\n",
       "      <td>5.389042</td>\n",
       "      <td>1.626925</td>\n",
       "      <td>2.321431</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.130501</td>\n",
       "      <td>2.120663</td>\n",
       "      <td>1.296481</td>\n",
       "      <td>1.456249</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009028</td>\n",
       "      <td>14.090569</td>\n",
       "      <td>3.312309</td>\n",
       "      <td>3.753741</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.962910</td>\n",
       "      <td>94.272351</td>\n",
       "      <td>7.710001</td>\n",
       "      <td>9.709395</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.799649</td>\n",
       "      <td>39.613602</td>\n",
       "      <td>5.353981</td>\n",
       "      <td>6.293934</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.137856</td>\n",
       "      <td>7.045263</td>\n",
       "      <td>2.276720</td>\n",
       "      <td>2.654291</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.762008</td>\n",
       "      <td>200.092281</td>\n",
       "      <td>12.148269</td>\n",
       "      <td>14.145398</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.884450</td>\n",
       "      <td>68.486433</td>\n",
       "      <td>6.201827</td>\n",
       "      <td>8.275653</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          r2         mse        mae       rmse  mda\n",
       "0 -10.146053   33.415565   5.512960   5.780620  0.2\n",
       "1  -1.069529   56.237796   5.979982   7.499186  0.8\n",
       "2  -0.021127    5.389042   1.626925   2.321431  0.4\n",
       "3  -0.130501    2.120663   1.296481   1.456249  0.6\n",
       "4   0.009028   14.090569   3.312309   3.753741  0.5\n",
       "5  -1.962910   94.272351   7.710001   9.709395  0.4\n",
       "6  -2.799649   39.613602   5.353981   6.293934  0.1\n",
       "7  -0.137856    7.045263   2.276720   2.654291  0.9\n",
       "8  -1.762008  200.092281  12.148269  14.145398  0.4\n",
       "9  -0.884450   68.486433   6.201827   8.275653  0.1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.882142</td>\n",
       "      <td>32.624367</td>\n",
       "      <td>5.155265</td>\n",
       "      <td>5.711774</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.331209</td>\n",
       "      <td>226.393918</td>\n",
       "      <td>13.871125</td>\n",
       "      <td>15.046392</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23.111338</td>\n",
       "      <td>127.248596</td>\n",
       "      <td>10.969855</td>\n",
       "      <td>11.280452</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105.082566</td>\n",
       "      <td>198.996161</td>\n",
       "      <td>13.894630</td>\n",
       "      <td>14.106600</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.882899</td>\n",
       "      <td>225.838039</td>\n",
       "      <td>14.093629</td>\n",
       "      <td>15.027909</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.778839</td>\n",
       "      <td>88.415652</td>\n",
       "      <td>8.128944</td>\n",
       "      <td>9.402960</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-5.033386</td>\n",
       "      <td>62.901640</td>\n",
       "      <td>7.252293</td>\n",
       "      <td>7.931055</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-13.167826</td>\n",
       "      <td>87.722892</td>\n",
       "      <td>8.714343</td>\n",
       "      <td>9.366050</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-7.015988</td>\n",
       "      <td>580.714283</td>\n",
       "      <td>22.745289</td>\n",
       "      <td>24.098014</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-28.119125</td>\n",
       "      <td>1058.274159</td>\n",
       "      <td>31.907340</td>\n",
       "      <td>32.531126</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           r2          mse        mae       rmse  mda\n",
       "0   -9.882142    32.624367   5.155265   5.711774  0.5\n",
       "1   -7.331209   226.393918  13.871125  15.046392  0.6\n",
       "2  -23.111338   127.248596  10.969855  11.280452  0.6\n",
       "3 -105.082566   198.996161  13.894630  14.106600  0.4\n",
       "4  -14.882899   225.838039  14.093629  15.027909  0.6\n",
       "5   -1.778839    88.415652   8.128944   9.402960  0.6\n",
       "6   -5.033386    62.901640   7.252293   7.931055  0.5\n",
       "7  -13.167826    87.722892   8.714343   9.366050  0.3\n",
       "8   -7.015988   580.714283  22.745289  24.098014  0.6\n",
       "9  -28.119125  1058.274159  31.907340  32.531126  0.6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5299999999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(llama_results[\"mda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\_auto_solvers.py:524: ModelFitWarning: Error fitting  ARIMA(5,0,0)(0,0,0)[0]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\_auto_solvers.py\", line 508, in _fit_candidate_model\n",
      "    fit.fit(y, X=X, **fit_params)\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\arima.py\", line 603, in fit\n",
      "    self._fit(y, X, **fit_args)\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\arima.py\", line 524, in _fit\n",
      "    fit, self.arima_res_ = _fit_wrapper()\n",
      "                           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pmdarima\\arima\\arima.py\", line 510, in _fit_wrapper\n",
      "    fitted = arima.fit(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\", line 704, in fit\n",
      "    mlefit = super(MLEModel, self).fit(start_params, method=method,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\model.py\", line 563, in fit\n",
      "    xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\optimizer.py\", line 241, in _fit\n",
      "    xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\optimizer.py\", line 651, in _fit_lbfgs\n",
      "    retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 237, in fmin_l_bfgs_b\n",
      "    res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 407, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 296, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 262, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 163, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 145, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\model.py\", line 531, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\", line 939, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py\", line 983, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py\", line 903, in _filter\n",
      "    self._initialize_state(prefix=prefix, complex_step=complex_step)\n",
      "  File \"C:\\Users\\topco\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\tsa\\statespace\\representation.py\", line 983, in _initialize_state\n",
      "    self._statespaces[prefix].initialize(self.initialization,\n",
      "  File \"statsmodels\\tsa\\statespace\\_representation.pyx\", line 1362, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels\\tsa\\statespace\\_initialization.pyx\", line 288, in statsmodels.tsa.statespace._initialization.dInitialization.initialize\n",
      "  File \"statsmodels\\tsa\\statespace\\_initialization.pyx\", line 406, in statsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\n",
      "  File \"statsmodels\\tsa\\statespace\\_tools.pyx\", line 1206, in statsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\n",
      "numpy.linalg.LinAlgError: LU decomposition error.\n",
      "\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n"
     ]
    }
   ],
   "source": [
    "r = get_tscv_results(simple_data, PREDICTION_HORIZON, CONTEXT_LENGTH, FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2': {'arima': {'fold_0': [-3.691877661141132],\n",
       "   'fold_1': [-0.010542006383208902],\n",
       "   'fold_2': [-5.611156232296624],\n",
       "   'fold_3': [-2.0666207482946946],\n",
       "   'fold_4': [-0.7687106529191812],\n",
       "   'fold_5': [-0.3431518091946324],\n",
       "   'fold_6': [-5.351096735700188],\n",
       "   'fold_7': [-1.6938904126202843],\n",
       "   'fold_8': [-0.011681380345721193],\n",
       "   'fold_9': [-4.330864243718463]},\n",
       "  'llama': {'fold_0': [-9.336629997575274],\n",
       "   'fold_1': [-179.7260621892066],\n",
       "   'fold_2': [-107.60443413307539],\n",
       "   'fold_3': [-115.009555818314],\n",
       "   'fold_4': [-4.876441039021601],\n",
       "   'fold_5': [-304.6272485868018],\n",
       "   'fold_6': [-67.11577380450797],\n",
       "   'fold_7': [-120.96634096008222],\n",
       "   'fold_8': [-102.0076103887577],\n",
       "   'fold_9': [-178.49412755448967]}},\n",
       " 'mse': {'arima': {'fold_0': [13.875785862988721],\n",
       "   'fold_1': [0.31214081152770684],\n",
       "   'fold_2': [5.642126724971973],\n",
       "   'fold_3': [2.991871755262922],\n",
       "   'fold_4': [123.78820905652573],\n",
       "   'fold_5': [3.945837239182269],\n",
       "   'fold_6': [51.01199731770291],\n",
       "   'fold_7': [13.30463379111579],\n",
       "   'fold_8': [6.3747059930477645],\n",
       "   'fold_9': [36.38447302355967]},\n",
       "  'llama': {'fold_0': [30.569608747303988],\n",
       "   'fold_1': [55.823488147561186],\n",
       "   'fold_2': [92.68575098547001],\n",
       "   'fold_3': [113.18181864725875],\n",
       "   'fold_4': [411.2793184380692],\n",
       "   'fold_5': [897.8548593890679],\n",
       "   'fold_6': [547.1057701069233],\n",
       "   'fold_7': [602.3695298495385],\n",
       "   'fold_8': [649.0612993691242],\n",
       "   'fold_9': [1225.0920194767984]}},\n",
       " 'mae': {'arima': {'fold_0': [3.299668014739723],\n",
       "   'fold_1': [0.4430380839316304],\n",
       "   'fold_2': [2.1825338679929396],\n",
       "   'fold_3': [1.4156159390302416],\n",
       "   'fold_4': [10.002442179429323],\n",
       "   'fold_5': [1.6468804626613671],\n",
       "   'fold_6': [6.562885693697486],\n",
       "   'fold_7': [2.8801263315627446],\n",
       "   'fold_8': [2.199529348756755],\n",
       "   'fold_9': [5.429148340103448]},\n",
       "  'llama': {'fold_0': [5.055035635804832],\n",
       "   'fold_1': [7.174409583547127],\n",
       "   'fold_2': [9.449094698692514],\n",
       "   'fold_3': [10.282028559654824],\n",
       "   'fold_4': [18.608818122339624],\n",
       "   'fold_5': [29.91127559911534],\n",
       "   'fold_6': [23.339065504861093],\n",
       "   'fold_7': [24.019161378244036],\n",
       "   'fold_8': [25.33469162337799],\n",
       "   'fold_9': [34.70191832806969]}},\n",
       " 'rmse': {'arima': {'fold_0': [3.7250215922848984],\n",
       "   'fold_1': [0.5586956340689507],\n",
       "   'fold_2': [2.3753161315858513],\n",
       "   'fold_3': [1.7297027939108274],\n",
       "   'fold_4': [11.126014967477158],\n",
       "   'fold_5': [1.9864131592350744],\n",
       "   'fold_6': [7.142268359401158],\n",
       "   'fold_7': [3.647551753041455],\n",
       "   'fold_8': [2.524818011866947],\n",
       "   'fold_9': [6.031954328703067]},\n",
       "  'llama': {'fold_0': [5.5289789968224685],\n",
       "   'fold_1': [7.471511771225498],\n",
       "   'fold_2': [9.627343921636434],\n",
       "   'fold_3': [10.638694405201173],\n",
       "   'fold_4': [20.280022643923974],\n",
       "   'fold_5': [29.9642263272234],\n",
       "   'fold_6': [23.390292219357228],\n",
       "   'fold_7': [24.543217593655857],\n",
       "   'fold_8': [25.476681482664183],\n",
       "   'fold_9': [35.00131453926836]}},\n",
       " 'mda': {'arima': {'fold_0': [1.0],\n",
       "   'fold_1': [1.0],\n",
       "   'fold_2': [0.0],\n",
       "   'fold_3': [0.0],\n",
       "   'fold_4': [0.0],\n",
       "   'fold_5': [0.0],\n",
       "   'fold_6': [1.0],\n",
       "   'fold_7': [0.0],\n",
       "   'fold_8': [0.0],\n",
       "   'fold_9': [0.0]},\n",
       "  'llama': {'fold_0': [0.0],\n",
       "   'fold_1': [1.0],\n",
       "   'fold_2': [1.0],\n",
       "   'fold_3': [0.0],\n",
       "   'fold_4': [0.0],\n",
       "   'fold_5': [1.0],\n",
       "   'fold_6': [1.0],\n",
       "   'fold_7': [0.0],\n",
       "   'fold_8': [0.0],\n",
       "   'fold_9': [0.0]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
